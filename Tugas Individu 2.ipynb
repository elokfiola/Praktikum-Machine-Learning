{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tugas Praktikum PM Modul 2\n",
        "Nama : Elok Fiola      \n",
        "NIM  : 122450051       \n",
        "Kelas : RC"
      ],
      "metadata": {
        "id": "xOy748dE-05F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Soal 1\n",
        "Menggunakan dataset 2(dua fitur kategorik dan satu fitur numerik) lakukan klasifikasi kelas dnegan data test harga Murah, jaka 5 km dan tidak ada angkuatan"
      ],
      "metadata": {
        "id": "46XWFG_T-_-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import library\n",
        "import numpy as np\n",
        "from math import sqrt, exp, pi"
      ],
      "metadata": {
        "id": "z6g9aCABCbN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset\n",
        "data = [\n",
        "    ['Murah', 4, 'Tidak', 'Ya'],\n",
        "    ['Sedang', 9, 'Tidak', 'Ya'],\n",
        "    ['Mahal',  3, 'Tidak', 'Ya'],\n",
        "    ['Mahal', 20, 'Tidak', 'Tidak'],\n",
        "    ['Mahal', 12, 'Tidak', 'Tidak'],\n",
        "    ['Sedang', 10, 'Ada', 'Tidak'],\n",
        "    ['Murah', 19, 'Ada', 'Tidak'],\n",
        "    ['Murah', 7, 'Tidak', 'Ya'],\n",
        "    ['Mahal', 8, 'Ada', 'Tidak'],\n",
        "    ['Sedang', 2, 'Ada', 'Ya']\n",
        "]"
      ],
      "metadata": {
        "id": "bFidrbMDCcvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_prior(data):\n",
        "  total = len(data)\n",
        "  ya_count = sum(1 for row in data if row[-1] == 'Ya')\n",
        "  tidak_count = total - ya_count\n",
        "  return ya_count / total, tidak_count / total"
      ],
      "metadata": {
        "id": "Trv5QvQFC6sF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hitung distribusi Gaussian untuk fitur numerik\n",
        "def calculate_gaussian_prob(x, mean, std):\n",
        "  exponent = exp(-((x - mean) ** 2 / (2 * std ** 2)))\n",
        "  return (1 / (sqrt(2 * pi) * std)) * exponent\n",
        "\n",
        "#Hitung mean dan std dev untuk fitur numerik\n",
        "def calculated_numerical_stats(data, feature_index, target_value):\n",
        "  filtered_data = [row[feature_index] for row in data if row[-1] == target_value]\n",
        "  mean = np.mean(filtered_data)\n",
        "  std = np.std(filtered_data)\n",
        "  return mean, std"
      ],
      "metadata": {
        "id": "piClL7WhCgIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_categorical_prob(data, feature_index, value, target_value): #Fixed typo in the parameter name (targer_value -> target_value)\n",
        "  filtered_data = [row for row in data if row[-1] == target_value] #Fixed typo in the variable name (now -> row)\n",
        "  count = sum(1 for row in filtered_data if row[feature_index] == value)\n",
        "  return count / len(filtered_data) if len(filtered_data) > 0 else 0"
      ],
      "metadata": {
        "id": "UMFz8iPPDd6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Klasifikasi Naive Bayes\n",
        "def naive_bayes_predict(data, harga, jarak, angkutan):\n",
        "  prior_ya, prior_tidak = calculate_prior(data)\n",
        "\n",
        "  #Probabilitas kondisional untuk Ya\n",
        "  p_harga_ya = calculate_categorical_prob(data, 0, harga, 'Ya')\n",
        "  mean_ya, std_ya = calculated_numerical_stats(data, 1, 'Ya') #fitur numerik\n",
        "  p_jarak_ya = calculate_gaussian_prob(jarak, mean_ya, std_ya) #fitur numerik\n",
        "  p_angkutan_ya = calculate_categorical_prob(data, 2, angkutan, 'Ya')\n",
        "\n",
        "  #Probabilitas kondisional untuk Tidak\n",
        "  p_harga_tidak = calculate_categorical_prob(data, 0, harga, 'Tidak')\n",
        "  mean_tidak, std_tidak = calculated_numerical_stats(data, 1, 'Tidak') #fitur numerik\n",
        "  p_jarak_tidak = calculate_gaussian_prob(jarak, mean_tidak, std_tidak) #fitur numerik\n",
        "  p_angkutan_tidak = calculate_categorical_prob(data, 2, angkutan, 'Tidak')\n",
        "\n",
        "  #Posterior untuk Ya dan Tidak\n",
        "  p_ya = prior_ya * p_harga_ya * p_jarak_ya * p_angkutan_ya\n",
        "  p_tidak = prior_tidak * p_harga_tidak * p_jarak_tidak * p_angkutan_tidak\n",
        "\n",
        "  return 'Ya' if p_ya > p_tidak else 'Tidak', p_ya, p_tidak"
      ],
      "metadata": {
        "id": "0_lrzecDCh9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediksi untuk harga \"Murah\", jarak, 5, dan angkutan \"Tidak\"\n",
        "prediction = naive_bayes_predict(data, 'Murah', 8, 'Tidak')\n",
        "prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_wn2ZjTCkHz",
        "outputId": "ab808b5f-9684-48bb-8e8e-a702943ffeb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Ya', 0.012629170661777364, 0.0016070401893203787)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Soal 2\n",
        "harga 35 juta, jarak 17, ada angkutan"
      ],
      "metadata": {
        "id": "gBeMRw2UCf0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import library\n",
        "import numpy as np\n",
        "from math import sqrt, exp, pi\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "fcetxChM_CD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = [\n",
        "    [70000000, 4, 'Tidak', 'Ya'],\n",
        "    [23000000, 9, 'Tidak', 'Ya'],\n",
        "    [104000000, 3,'Tidak', 'Ya'],\n",
        "    [80000000, 20, 'Tidak', 'Tidak'],\n",
        "    [54000000, 12, 'Tidak', 'Tidak'],\n",
        "    [60000000, 10, 'Ada', 'Tidak'],\n",
        "    [31000000, 19, 'Ada', 'Tidak'],\n",
        "    [37000000, 7, 'Tidak', 'Ya'],\n",
        "    [22000000, 8, 'Ada', 'Tidak'],\n",
        "    [120000000, 2, 'Ada', 'Tidak']\n",
        "]"
      ],
      "metadata": {
        "id": "OrPoQYfP_2-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hitung distribusi Gaussian untuk fitur numerik\n",
        "def calculate_gaussian_prob2(x, mean, std):\n",
        "  exponent2 = exp(-((x - mean) ** 2 / (2 * std ** 2)))\n",
        "  return (1 / (sqrt(2 * pi) * std)) * exponent2\n",
        "\n",
        "#Hitung mean dan std dev untuk fitur numerik\n",
        "def calculated_numerical_stats2(data2, feature_index, target_value):\n",
        "  filtered_data2 = [row[feature_index] for row in data2 if row[-1] == target_value]\n",
        "  mean2 = np.mean(filtered_data2)\n",
        "  std2 = np.std(filtered_data2)\n",
        "  return mean2, std2"
      ],
      "metadata": {
        "id": "vvTF2PLMBPxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_categorical_prob2(data2, feature_index2, value2, target_value2): #Fixed typo in the parameter name (targer_value -> target_value)\n",
        "  filtered_data2 = [row for row in data2 if row[-1] == target_value2] #Fixed typo in the variable name (now -> row)\n",
        "  count2 = sum(1 for row in filtered_data2 if row[feature_index2] == value2) # Changed 'value' to 'value2'\n",
        "  return count2 / len(filtered_data2) if len(filtered_data2) > 0 else 0"
      ],
      "metadata": {
        "id": "aCkKj28HB_Pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ya_count = sum(1 for row in data if row[-1] == 'Ya')"
      ],
      "metadata": {
        "id": "2LAjDXBqJ_DC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Klasifikasi Naive Bayes\n",
        "def naive_bayes_predict2(data2, harga2, jarak2, angkutan2):\n",
        "  prior_ya2, prior_tidak2 = calculate_prior(data2)\n",
        "\n",
        "  # Probabilitas kondisional untuk Ya\n",
        "  mean_ya2, std_ya2 = calculated_numerical_stats2(data2, 1, 'Ya')\n",
        "  p_harga_ya2 = calculate_gaussian_prob2(harga2, mean_ya2, std_ya2)\n",
        "  p_jarak_ya2 = calculate_gaussian_prob2(jarak2, mean_ya2, std_ya2)\n",
        "  p_angkutan_ya2= calculate_categorical_prob2(data2, 2, angkutan2, 'Ya')\n",
        "\n",
        "  # Probabilitas kondisional untuk Tidak\n",
        "  mean_tidak2, std_tidak2 = calculated_numerical_stats2(data2, 1, 'Tidak')\n",
        "  p_harga_tidak2 = calculate_categorical_prob2(data2, 0, harga2, 'Tidak')\n",
        "  p_jarak_tidak2 = calculate_gaussian_prob2(jarak2, mean_tidak2, std_tidak2)\n",
        "  p_angkutan_tidak2 = calculate_categorical_prob2(data2, 2, angkutan2, 'Tidak')\n",
        "\n",
        "  # Posterior untuk Ya dan Tidak\n",
        "  p_ya = prior_ya2 * p_harga_ya2 * p_jarak_ya2 * p_angkutan_ya2\n",
        "  p_tidak = prior_tidak2 * p_harga_tidak2 * p_jarak_tidak2 * p_angkutan_tidak2\n",
        "\n",
        "  return 'Ya' if p_ya > p_tidak else 'Tidak', p_ya, p_tidak"
      ],
      "metadata": {
        "id": "mi96AuHWKCwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi untuk harga \"Murah\", jarak 17, dan angkutan \"Ada\"\n",
        "prediction2 = naive_bayes_predict2(data2, 35000000, 17, 'Ada')\n",
        "prediction2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQHEJIeDKkS4",
        "outputId": "35d7c569-6b20-48f1-efda-e5087eb907da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Tidak', 0.0, 0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Soal 3"
      ],
      "metadata": {
        "id": "344HtnSTFxfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "drfTx8UqFxAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert dataframe data2\n",
        "data2 = pd.DataFrame(data2)\n",
        "\n",
        "#Split data into independent/ dependent variables\n",
        "X = data2.iloc[:, :-1].values #variabel bebas\n",
        "y = data2.iloc[:, -1].values #variabel terikat"
      ],
      "metadata": {
        "id": "LiE_wuurF2vJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train/ test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=True)"
      ],
      "metadata": {
        "id": "0t6dAqq7GCDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scale dataset\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "JgixSHsfGNnj",
        "outputId": "f0d32562-7b5d-4f38-9753-f9873a1597d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'Tidak'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-ea3e6317eb5f>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#scale dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_fit_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer_skip_nested_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \"\"\"\n\u001b[1;32m    913\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Tidak'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Assuming data2 is your DataFrame\n",
        "data2 = pd.get_dummies(data2, columns=['Jarak'])"
      ],
      "metadata": {
        "id": "lg10Rlf2GV2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "https://colab.research.google.com/drive/13pWoShrJTj3EYCc6Nj4XePGg7pAl8hj5?usp=sharing"
      ],
      "metadata": {
        "id": "Ee0nwT3JIpeu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}